{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
    "\n",
    "### ðŸ“˜ **Class**: AI Engineering\n",
    "\n",
    "### ðŸ“‹ **Homework 3**: Improving Lexical Search\n",
    "\n",
    "### ðŸ“… **Due Date**: Day of Lecture 4, 11:59 PM\n",
    "\n",
    "\n",
    "**Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "You'll apply what we covered in Lecture 3 (Lexical Search & BM25) to a real e-commerce search problem using the **WANDS dataset** \n",
    "- WANDS stands for Wayfair Annotated Dataset. It's a dataset of furniture products and search queries, along with human relevance judgments.\n",
    "\n",
    "You will:\n",
    "1. **Build a search engine** from scratch using BM25.\n",
    "2. **Learn how to evaluate search results** using NDCG â€” a metric for measuring search quality\n",
    "3. **Attempt to improve your search engine** by adding multiple fields\n",
    "4. **Use LLMs to improve your search engine** by adding simple query understanding\n",
    "\n",
    "Yes, *you* will do all these things. Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Environment Setup\n",
    "\n",
    "First, let's set up your environment and verify everything works.\n",
    "\n",
    "### 1a. Install dependencies and verify imports\n",
    "\n",
    "Run `uv add pystemmer` in your terminal to add the Snowball stemmer. Then run the cell below to verify all imports work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "from pathlib import Path\n",
    "import Stemmer \n",
    "import litellm\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydantic\")\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### 1b. Verify API keys\n",
    "\n",
    "Test that your API keys work by making a simple call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560cc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API working!\n"
     ]
    }
   ],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say 'API working!' and nothing else.\"}],\n",
    "    max_tokens=20\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Load and Explore the WANDS Dataset\n",
    "\n",
    "The **WANDS dataset** (Wayfair Annotated Dataset) contains:\n",
    "- 43K furniture products from Wayfair\n",
    "- 480 real search queries\n",
    "- 233K human relevance judgments (query-product pairs)\n",
    "\n",
    "This is a real-world search benchmark used to evaluate e-commerce search systems!\n",
    "\n",
    "**Data Source**: [WANDS on GitHub](https://github.com/wayfair/WANDS)\n",
    "\n",
    "The data files are pre-downloaded in the `data/` directory:\n",
    "- `wayfair-products.csv` - Product catalog\n",
    "- `wayfair-queries.csv` - Search queries\n",
    "- `wayfair-labels.csv` - Relevance judgments\n",
    "\n",
    "### Data Loading Functions (provided)\n",
    "\n",
    "Run the cell below to define the loading functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions (provided)\n",
    "# Note: Data from WANDS (Wayfair Annotated Dataset)\n",
    "# Source: https://github.com/wayfair/WANDS\n",
    "\n",
    "def load_wands_products(data_dir: str = \"../data\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load WANDS products from local file.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the data directory containing wayfair-products.csv\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with product information including product_id, product_name,\n",
    "        product_class, category_hierarchy, product_description, etc.\n",
    "    \"\"\"\n",
    "    filepath = Path(data_dir) / \"wayfair-products.csv\"\n",
    "    products = pd.read_csv(filepath, sep='\\t')\n",
    "    products = products.rename(columns={'category hierarchy': 'category_hierarchy'})\n",
    "    return products\n",
    "\n",
    "def load_wands_queries(data_dir: str = \"../data\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load WANDS queries from local file.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the data directory containing wayfair-queries.csv\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with query_id and query columns\n",
    "    \"\"\"\n",
    "    filepath = Path(data_dir) / \"wayfair-queries.csv\"\n",
    "    queries = pd.read_csv(filepath, sep='\\t')\n",
    "    return queries\n",
    "\n",
    "def load_wands_labels(data_dir: str = \"../data\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load WANDS relevance labels from local file.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to the data directory containing wayfair-labels.csv\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with query_id, product_id, label (Exact/Partial/Irrelevant),\n",
    "        and grade (2/1/0) columns\n",
    "    \"\"\"\n",
    "    filepath = Path(data_dir) / \"wayfair-labels.csv\"\n",
    "    labels = pd.read_csv(filepath, sep='\\t')\n",
    "    grade_map = {'Exact': 2, 'Partial': 1, 'Irrelevant': 0}\n",
    "    labels['grade'] = labels['label'].map(grade_map)\n",
    "    return labels\n",
    "\n",
    "print(\"Loading functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 2a. Load the data\n",
    "\n",
    "Use the provided functions to load all three datasets. Print the number of rows in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products: 42994 rows\n",
      "Queries: 480 rows\n",
      "Labels: 233448 rows\n"
     ]
    }
   ],
   "source": [
    "products = load_wands_products(data_dir=\"./data\")\n",
    "queries = load_wands_queries(data_dir=\"./data\")\n",
    "labels = load_wands_labels(data_dir=\"./data\")\n",
    "\n",
    "print(f\"Products: {len(products)} rows\")\n",
    "print(f\"Queries: {len(queries)} rows\")\n",
    "print(f\"Labels: {len(labels)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2b. Explore products\n",
    "\n",
    "List the available columns, and display a few sample products. \n",
    "\n",
    "Which columns might be useful for search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "['product_id', 'product_name', 'product_class', 'category_hierarchy', 'product_description', 'product_features', 'rating_count', 'average_rating', 'review_count']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available columns:\")\n",
    "print(products.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_class</th>\n",
       "      <th>category_hierarchy</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_features</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>solid wood platform bed</td>\n",
       "      <td>Beds</td>\n",
       "      <td>Furniture / Bedroom Furniture / Beds &amp; Headboa...</td>\n",
       "      <td>good , deep sleep can be quite difficult to ha...</td>\n",
       "      <td>overallwidth-sidetoside:64.7|dsprimaryproducts...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>all-clad 7 qt . slow cooker</td>\n",
       "      <td>Slow Cookers</td>\n",
       "      <td>Kitchen &amp; Tabletop / Small Kitchen Appliances ...</td>\n",
       "      <td>create delicious slow-cooked meals , from tend...</td>\n",
       "      <td>capacityquarts:7|producttype : slow cooker|pro...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>all-clad electrics 6.5 qt . slow cooker</td>\n",
       "      <td>Slow Cookers</td>\n",
       "      <td>Kitchen &amp; Tabletop / Small Kitchen Appliances ...</td>\n",
       "      <td>prepare home-cooked meals on any schedule with...</td>\n",
       "      <td>features : keep warm setting|capacityquarts:6....</td>\n",
       "      <td>208.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>all-clad all professional tools pizza cutter</td>\n",
       "      <td>Slicers, Peelers And Graters</td>\n",
       "      <td>Browse By Brand / All-Clad</td>\n",
       "      <td>this original stainless tool was designed to c...</td>\n",
       "      <td>overallwidth-sidetoside:3.5|warrantylength : l...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>baldwin prestige alcott passage knob with roun...</td>\n",
       "      <td>Door Knobs</td>\n",
       "      <td>Home Improvement / Doors &amp; Door Hardware / Doo...</td>\n",
       "      <td>the hardware has a rich heritage of delivering...</td>\n",
       "      <td>compatibledoorthickness:1.375 '' |countryofori...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                       product_name  \\\n",
       "0           0                            solid wood platform bed   \n",
       "1           1                        all-clad 7 qt . slow cooker   \n",
       "2           2            all-clad electrics 6.5 qt . slow cooker   \n",
       "3           3       all-clad all professional tools pizza cutter   \n",
       "4           4  baldwin prestige alcott passage knob with roun...   \n",
       "\n",
       "                  product_class  \\\n",
       "0                          Beds   \n",
       "1                  Slow Cookers   \n",
       "2                  Slow Cookers   \n",
       "3  Slicers, Peelers And Graters   \n",
       "4                    Door Knobs   \n",
       "\n",
       "                                  category_hierarchy  \\\n",
       "0  Furniture / Bedroom Furniture / Beds & Headboa...   \n",
       "1  Kitchen & Tabletop / Small Kitchen Appliances ...   \n",
       "2  Kitchen & Tabletop / Small Kitchen Appliances ...   \n",
       "3                         Browse By Brand / All-Clad   \n",
       "4  Home Improvement / Doors & Door Hardware / Doo...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  good , deep sleep can be quite difficult to ha...   \n",
       "1  create delicious slow-cooked meals , from tend...   \n",
       "2  prepare home-cooked meals on any schedule with...   \n",
       "3  this original stainless tool was designed to c...   \n",
       "4  the hardware has a rich heritage of delivering...   \n",
       "\n",
       "                                    product_features  rating_count  \\\n",
       "0  overallwidth-sidetoside:64.7|dsprimaryproducts...          15.0   \n",
       "1  capacityquarts:7|producttype : slow cooker|pro...         100.0   \n",
       "2  features : keep warm setting|capacityquarts:6....         208.0   \n",
       "3  overallwidth-sidetoside:3.5|warrantylength : l...          69.0   \n",
       "4  compatibledoorthickness:1.375 '' |countryofori...          70.0   \n",
       "\n",
       "   average_rating  review_count  \n",
       "0             4.5          15.0  \n",
       "1             2.0          98.0  \n",
       "2             3.0         181.0  \n",
       "3             4.5          42.0  \n",
       "4             5.0          42.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful search fields:\n",
      "1. product_name - main title\n",
      "2. product_description - detailed text\n",
      "3. product_class - product category\n",
      "4. category_hierarchy - full category path\n"
     ]
    }
   ],
   "source": [
    "print(\"Useful search fields:\")\n",
    "print(\"1. product_name - main title\")\n",
    "print(\"2. product_description - detailed text\")\n",
    "print(\"3. product_class - product category\")\n",
    "print(\"4. category_hierarchy - full category path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 2c. Understand relevance judgments\n",
    "\n",
    "The `labels` dataset contains human judgments of relevance. In particular, for each query-product pair, it contains:\n",
    "| Label        | Grade | Description                                 |\n",
    "|--------------|-------|---------------------------------------------|\n",
    "| Exact        |   2   | This product is exactly what the user wants |\n",
    "| Partial      |   1   | This product is somewhat relevant           |\n",
    "| Irrelevant   |   0   | This product doesn't match the query        |\n",
    "\n",
    "First, let's look at the distribution of grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade distribution:\n",
      "grade\n",
      "2     25614\n",
      "1    146633\n",
      "0     61201\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "Partial       146633\n",
      "Irrelevant     61201\n",
      "Exact          25614\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 2c: Understand judgments\n",
    "\n",
    "print(\"Grade distribution:\")\n",
    "print(labels['grade'].value_counts().sort_index(ascending=False))\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(labels['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Build and Run BM25 Search\n",
    "\n",
    "Now let's build a BM25 search engine! We'll use the same concepts from Lecture 3.\n",
    "\n",
    "### Provided Functions\n",
    "\n",
    "We're giving you these functions to work with. Run the next cell to define them, then look at the examples.\n",
    "\n",
    "| Function | What it does |\n",
    "|----------|--------------|\n",
    "| `snowball_tokenize(text)` | Tokenizes text, removes punctuation, stems words |\n",
    "| `build_index(docs, tokenizer)` | Builds an inverted index from a list of documents |\n",
    "| `get_tf(term, doc_id, index)` | Gets term frequency for a term in a document |\n",
    "| `get_df(term, index)` | Gets document frequency for a term (how many docs contain the term) |\n",
    "| `bm25_idf(df, num_docs)` | Calculates the IDF component of BM25 |\n",
    "| `bm25_tf(tf, doc_len, avg_doc_len)` | Calculates the TF normalization for BM25 |\n",
    "| `score_bm25(query, index, ...)` | Scores all documents for a query using BM25 |\n",
    "| `search_products(query, ...)` | Searches and returns top-k results |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Provided functions - run this cell to define them\n",
    "\n",
    "stemmer = Stemmer.Stemmer('english')\n",
    "punct_trans = str.maketrans({key: ' ' for key in string.punctuation})\n",
    "\n",
    "def snowball_tokenize(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Tokenize text with Snowball stemming.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to tokenize\n",
    "        \n",
    "    Returns:\n",
    "        List of stemmed tokens\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return []\n",
    "    text = str(text).translate(punct_trans)\n",
    "    tokens = text.lower().split()\n",
    "    return [stemmer.stemWord(token) for token in tokens]\n",
    "\n",
    "def build_index(docs: list[str], tokenizer) -> tuple[dict, list[int]]:\n",
    "    \"\"\"\n",
    "    Build an inverted index from a list of documents.\n",
    "    \n",
    "    Args:\n",
    "        docs: List of document strings to index\n",
    "        tokenizer: Function that takes text and returns list of tokens\n",
    "        \n",
    "    Returns:\n",
    "        index: dict mapping term -> {doc_id: term_count}\n",
    "        doc_lengths: list of document lengths (in tokens)\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "    doc_lengths = []\n",
    "    \n",
    "    for doc_id, doc in enumerate(docs):\n",
    "        tokens = tokenizer(doc)\n",
    "        doc_lengths.append(len(tokens))\n",
    "        term_counts = Counter(tokens)\n",
    "        \n",
    "        for term, count in term_counts.items():\n",
    "            if term not in index:\n",
    "                index[term] = {}\n",
    "            index[term][doc_id] = count\n",
    "    \n",
    "    return index, doc_lengths\n",
    "\n",
    "def get_tf(term: str, doc_id: int, index: dict) -> int:\n",
    "    \"\"\"\n",
    "    Get term frequency for a term in a document.\n",
    "    \n",
    "    Args:\n",
    "        term: The term to look up\n",
    "        doc_id: The document ID\n",
    "        index: The inverted index\n",
    "        \n",
    "    Returns:\n",
    "        Term frequency (count), or 0 if not found\n",
    "    \"\"\"\n",
    "    if term in index and doc_id in index[term]:\n",
    "        return index[term][doc_id]\n",
    "    return 0\n",
    "\n",
    "def get_df(term: str, index: dict) -> int:\n",
    "    \"\"\"\n",
    "    Get document frequency for a term.\n",
    "    \n",
    "    Args:\n",
    "        term: The term to look up\n",
    "        index: The inverted index\n",
    "        \n",
    "    Returns:\n",
    "        Number of documents containing the term\n",
    "    \"\"\"\n",
    "    if term in index:\n",
    "        return len(index[term])\n",
    "    return 0\n",
    "\n",
    "def bm25_idf(df: int, num_docs: int) -> float:\n",
    "    \"\"\"\n",
    "    BM25 IDF formula.\n",
    "    \n",
    "    Args:\n",
    "        df: Document frequency\n",
    "        num_docs: Total number of documents\n",
    "        \n",
    "    Returns:\n",
    "        IDF score\n",
    "    \"\"\"\n",
    "    return np.log((num_docs - df + 0.5) / (df + 0.5) + 1)\n",
    "\n",
    "def bm25_tf(tf: int, doc_len: int, avg_doc_len: float, k1: float = 1.2, b: float = 0.75) -> float:\n",
    "    \"\"\"\n",
    "    BM25 TF normalization.\n",
    "    \n",
    "    Args:\n",
    "        tf: Term frequency\n",
    "        doc_len: Document length in tokens\n",
    "        avg_doc_len: Average document length\n",
    "        k1: Saturation parameter (default 1.2)\n",
    "        b: Length normalization (default 0.75)\n",
    "        \n",
    "    Returns:\n",
    "        Normalized TF score\n",
    "    \"\"\"\n",
    "    return (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * doc_len / avg_doc_len))\n",
    "\n",
    "def score_bm25(query: str, index: dict, num_docs: int, doc_lengths: list[int], \n",
    "               tokenizer, k1: float = 1.2, b: float = 0.75) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Score all documents using BM25.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        index: Inverted index\n",
    "        num_docs: Total number of documents\n",
    "        doc_lengths: List of document lengths\n",
    "        tokenizer: Tokenization function\n",
    "        \n",
    "    Returns:\n",
    "        Array of scores for each document\n",
    "    \"\"\"\n",
    "    query_tokens = tokenizer(query)\n",
    "    scores = np.zeros(num_docs)\n",
    "    avg_doc_len = np.mean(doc_lengths) if doc_lengths else 1.0\n",
    "    \n",
    "    for token in query_tokens:\n",
    "        df = get_df(token, index)\n",
    "        if df == 0:\n",
    "            continue\n",
    "        \n",
    "        idf = bm25_idf(df, num_docs)\n",
    "        \n",
    "        if token in index:\n",
    "            for doc_id, tf in index[token].items():\n",
    "                tf_norm = bm25_tf(tf, doc_lengths[doc_id], avg_doc_len, k1, b)\n",
    "                scores[doc_id] += idf * tf_norm\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def search_products(query: str, products_df: pd.DataFrame, index: dict, \n",
    "                    doc_lengths: list[int], tokenizer, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Search products and return top-k results.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        products_df: DataFrame of products\n",
    "        index: Inverted index\n",
    "        doc_lengths: Document lengths\n",
    "        tokenizer: Tokenization function\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with top-k products and scores\n",
    "    \"\"\"\n",
    "    scores = score_bm25(query, index, len(products_df), doc_lengths, tokenizer)\n",
    "    top_k_idx = np.argsort(-scores)[:k]\n",
    "    \n",
    "    results = products_df.iloc[top_k_idx].copy()\n",
    "    results['score'] = scores[top_k_idx]\n",
    "    results['rank'] = range(1, k + 1)\n",
    "    return results\n",
    "\n",
    "print(\"All functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. snowball_tokenize('Running shoes are amazing!')\n",
      "   -> ['run', 'shoe', 'are', 'amaz']\n",
      "   Notice: 'Running' -> 'run', 'shoes' -> 'shoe', 'amazing' -> 'amaz'\n",
      "\n",
      "2. build_index(['red shoe', 'blue shoe', 'red hat'], tokenizer)\n",
      "   Index: {'red': {0: 1, 2: 1}, 'shoe': {0: 1, 1: 1}, 'blue': {1: 1}, 'hat': {2: 1}}\n",
      "   Lengths: [2, 2, 2]\n",
      "\n",
      "3. get_tf('red', doc_id=0, tiny_index)\n",
      "   -> 1  (doc 0 = 'red shoe' has 1 'red')\n",
      "\n",
      "4. get_df('red', tiny_index)\n",
      "   -> 2  ('red' appears in 2 documents)\n",
      "\n",
      "5. bm25_idf(df=100, num_docs=10000)\n",
      "   -> 4.6003  (term in 100 of 10000 docs)\n",
      "\n",
      "6. bm25_tf(tf=3, doc_len=50, avg_doc_len=100)\n",
      "   -> 1.7600  (short doc gets boosted)\n",
      "\n",
      "We'll use score_bm25() and search_products() in Task 3a!\n"
     ]
    }
   ],
   "source": [
    "# Examples of each function\n",
    "\n",
    "# 1. snowball_tokenize - tokenizes and stems text\n",
    "print(\"1. snowball_tokenize('Running shoes are amazing!')\")\n",
    "print(f\"   -> {snowball_tokenize('Running shoes are amazing!')}\")\n",
    "print(\"   Notice: 'Running' -> 'run', 'shoes' -> 'shoe', 'amazing' -> 'amaz'\")\n",
    "\n",
    "# 2. build_index - builds inverted index (we'll use a tiny example)\n",
    "tiny_docs = [\"red shoe\", \"blue shoe\", \"red hat\"]\n",
    "tiny_index, tiny_lengths = build_index(tiny_docs, snowball_tokenize)\n",
    "print(\"\\n2. build_index(['red shoe', 'blue shoe', 'red hat'], tokenizer)\")\n",
    "print(f\"   Index: {tiny_index}\")\n",
    "print(f\"   Lengths: {tiny_lengths}\")\n",
    "\n",
    "# 3. get_tf - get term frequency\n",
    "print(\"\\n3. get_tf('red', doc_id=0, tiny_index)\")\n",
    "print(f\"   -> {get_tf('red', 0, tiny_index)}  (doc 0 = 'red shoe' has 1 'red')\")\n",
    "\n",
    "# 4. get_df - get document frequency  \n",
    "print(\"\\n4. get_df('red', tiny_index)\")\n",
    "print(f\"   -> {get_df('red', tiny_index)}  ('red' appears in 2 documents)\")\n",
    "\n",
    "# 5. bm25_idf - calculate IDF (rare terms get higher scores)\n",
    "print(\"\\n5. bm25_idf(df=100, num_docs=10000)\")\n",
    "print(f\"   -> {bm25_idf(100, 10000):.4f}  (term in 100 of 10000 docs)\")\n",
    "\n",
    "# 6. bm25_tf - normalize term frequency by document length\n",
    "print(\"\\n6. bm25_tf(tf=3, doc_len=50, avg_doc_len=100)\")\n",
    "print(f\"   -> {bm25_tf(3, 50, 100):.4f}  (short doc gets boosted)\")\n",
    "\n",
    "# 7-8. score_bm25 and search_products - we'll use these next!\n",
    "print(\"\\nWe'll use score_bm25() and search_products() in Task 3a!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 3a. Create BM25 index for product_name\n",
    "\n",
    "Build an inverted index for the `product_name` field and run a sample search for a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'world', 'this', 'is', 'a', 'test']\n",
      "['star', 'wars', 'rug']\n"
     ]
    }
   ],
   "source": [
    "# Task 3a: Implement tokenizer\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Tokenize text by:\n",
    "    1. Converting to lowercase\n",
    "    2. Removing punctuation\n",
    "    3. Splitting on whitespace\n",
    "    \"\"\"\n",
    "    if pd.isna(text):  # Handle missing values\n",
    "        return []\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Split on whitespace\n",
    "    tokens = text.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Test it\n",
    "print(tokenize(\"Hello, World! This is a TEST.\"))\n",
    "print(tokenize(\"Star Wars Rug\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 3b. Add product_description to search\n",
    "\n",
    "Create a second index for `product_description` and combine scores from both fields.\n",
    "\n",
    "**Hint**: You can combine the two scores by adding them together. This is like multi-field search from Lecture 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: {'red': {0: 1, 2: 1}, 'leather': {0: 1, 1: 1}, 'sofa': {0: 1}, 'blue': {1: 1}, 'chair': {1: 1, 2: 1}, 'wooden': {2: 1}}\n",
      "Doc lengths: [3, 3, 3]\n",
      "\n",
      "Documents containing 'leather': {0: 1, 1: 1}\n",
      "Documents containing 'red': {0: 1, 2: 1}\n"
     ]
    }
   ],
   "source": [
    "# Task 3b: Implement build_index\n",
    "\n",
    "def build_index(documents: list[str], tokenizer) -> tuple[dict, list[int]]:\n",
    "    \"\"\"\n",
    "    Build an inverted index from a list of documents.\n",
    "    \n",
    "    Args:\n",
    "        documents: List of document strings\n",
    "        tokenizer: Function to tokenize text\n",
    "        \n",
    "    Returns:\n",
    "        index: dict mapping {term: {doc_id: count}}\n",
    "        doc_lengths: list of document lengths (number of tokens)\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "    doc_lengths = []\n",
    "    \n",
    "    for doc_id, doc in enumerate(documents):\n",
    "        tokens = tokenizer(doc)\n",
    "        doc_lengths.append(len(tokens))\n",
    "        \n",
    "        # Count tokens in this document\n",
    "        token_counts = Counter(tokens)\n",
    "        \n",
    "        # Add to inverted index\n",
    "        for token, count in token_counts.items():\n",
    "            if token not in index:\n",
    "                index[token] = {}\n",
    "            index[token][doc_id] = count\n",
    "    \n",
    "    return index, doc_lengths\n",
    "\n",
    "# Test it\n",
    "test_docs = [\n",
    "    \"red leather sofa\",\n",
    "    \"blue leather chair\", \n",
    "    \"red wooden chair\"\n",
    "]\n",
    "\n",
    "test_index, test_lengths = build_index(test_docs, tokenize)\n",
    "\n",
    "print(\"Index:\", test_index)\n",
    "print(\"Doc lengths:\", test_lengths)\n",
    "print(\"\\nDocuments containing 'leather':\", test_index.get('leather', {}))\n",
    "print(\"Documents containing 'red':\", test_index.get('red', {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81dd15c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 42994 products\n",
      "Unique terms in index: 29617\n",
      "Average product name length: 6.27 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Build index on product_name field\n",
    "product_name_index, product_name_lengths = build_index(\n",
    "    products['product_name'].tolist(), \n",
    "    tokenize\n",
    ")\n",
    "\n",
    "print(f\"Indexed {len(products)} products\")\n",
    "print(f\"Unique terms in index: {len(product_name_index)}\")\n",
    "print(f\"Average product name length: {np.mean(product_name_lengths):.2f} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Measuring Search Quality\n",
    "\n",
    "We built a little search engine. How do we know if it's any good?\n",
    "\n",
    "Consider two search results for \"coffee table\":\n",
    "\n",
    "| Ranking A | Ranking B |\n",
    "|-----------|-----------|\n",
    "| 1. Wooden Coffee Table (Exact) | 1. Metal Lamp (Irrelevant) |\n",
    "| 2. Glass Coffee Table (Exact) | 2. Wooden Coffee Table (Exact) |\n",
    "| 3. Metal Lamp (Irrelevant) | 3. Glass Coffee Table (Exact) |\n",
    "\n",
    "### A. Precision\n",
    "\n",
    "One way to measure the quality of a ranking is to look at the precision within these first 3 results. \n",
    "- Precision is the ratio of relevant results to total results at position k.\n",
    "- We call this precision@3, and more generally precision@k is the ratio of relevant results to total results at position k.\n",
    "  \n",
    "In this scenario, if we consider \"exact\" results as relevant, then both rankings have precision@3 = 2/3.\n",
    "\n",
    "### B. DCG\n",
    "\n",
    "Both rankings have the same precision, but Ranking A is clearly better \n",
    "- users look at results from the top down, and most people never scroll past the first few results\n",
    "- as such, rankings that return relevant results earlier are better\n",
    "\n",
    "So we need a metric that rewards **relevant** results, and rewards them **more** when they appear at the **top**\n",
    "\n",
    "NDCG (Normalized Discounted Cumulative Gain) does this by giving each result a \"gain\" based on its relevance, then **discounting** that gain based on position.\n",
    "\n",
    "**The formula** for each result at position $i$:\n",
    "\n",
    "$$\\text{gain}_i = \\frac{2^{\\text{relevance}} - 1}{\\log_2(i + 1)}$$\n",
    "\n",
    "- **Numerator** $(2^{\\text{relevance}} - 1)$: How relevant is this result?\n",
    "  - Irrelevant (0): $2^0 - 1 = 0$ (no gain)\n",
    "  - Partial (1): $2^1 - 1 = 1$ (some gain)\n",
    "  - Exact (2): $2^2 - 1 = 3$ (lots of gain!)\n",
    "  \n",
    "- **Denominator** $\\log_2(i + 1)$: The \"discount\" based on position\n",
    "  - Position 1: $\\log_2(2) = 1$ (no discount)\n",
    "  - Position 2: $\\log_2(3) = 1.58$ (small discount)\n",
    "  - Position 10: $\\log_2(11) = 3.46$ (bigger discount)\n",
    "\n",
    "**DCG** sums the discounted score for each result\n",
    "\n",
    "$$\\text{DCG} = \\sum_{i=1}^{k} \\frac{2^{\\text{relevance}_i} - 1}{\\log_2(i + 1)}$$\n",
    "\n",
    "### 3. NDCG: Normalized DCG\n",
    "\n",
    "One problem with DCG is that the score depends on how many relevant products exist. \n",
    "- A query with 10 exact matches will have a higher DCG than one with only 2, even if both rankings are \"perfect.\"\n",
    "\n",
    "One solution is to normalize by the *ideal* DCG â€” what the score would be if we ranked everything perfectly (all relevant results at the top).\n",
    "\n",
    "$$\\text{NDCG} = \\frac{\\text{DCG}}{\\text{Ideal DCG}}$$\n",
    "\n",
    "- **NDCG = 1.0**: Perfect -- best possible order\n",
    "- **NDCG = 0.5**: OK -- some good some bad\n",
    "- **NDCG = 0.0**: Worst -- results are irrelevant\n",
    "\n",
    "**Read the above carefully.** In the next cell, explain in your own words: why does the discount formula use $\\log_2$? What happens to results at position 1 vs position 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF of 'coffee' in doc 0: 0\n",
      "DF of 'coffee': 1585\n",
      "IDF of 'coffee': 3.2626\n"
     ]
    }
   ],
   "source": [
    "# Task 4a: Implement helper functions\n",
    "\n",
    "def get_tf(term: str, doc_id: int, index: dict) -> int:\n",
    "    \"\"\"Get term frequency (count) for a term in a document.\"\"\"\n",
    "    if term not in index:\n",
    "        return 0\n",
    "    return index[term].get(doc_id, 0)\n",
    "\n",
    "def get_df(term: str, index: dict) -> int:\n",
    "    \"\"\"Get document frequency (number of docs containing term).\"\"\"\n",
    "    if term not in index:\n",
    "        return 0\n",
    "    return len(index[term])\n",
    "\n",
    "def bm25_idf(df: int, num_docs: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate BM25 IDF score.\n",
    "    Formula: log((num_docs - df + 0.5) / (df + 0.5))\n",
    "    \"\"\"\n",
    "    if df == 0:\n",
    "        return 0.0\n",
    "    return np.log((num_docs - df + 0.5) / (df + 0.5))\n",
    "\n",
    "# Test the functions\n",
    "print(f\"TF of 'coffee' in doc 0: {get_tf('coffee', 0, product_name_index)}\")\n",
    "print(f\"DF of 'coffee': {get_df('coffee', product_name_index)}\")\n",
    "print(f\"IDF of 'coffee': {bm25_idf(get_df('coffee', product_name_index), len(products)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### 4b. Calculate NDCG by hand\n",
    "\n",
    "Let's work through an example step by step.\n",
    "\n",
    "**Scenario**: You search for \"wooden coffee table\" and get these results:\n",
    "\n",
    "| Position | Product | Relevance |\n",
    "|----------|---------|----------|\n",
    "| 1 | Glass Coffee Table | Partial (1) |\n",
    "| 2 | Wooden Coffee Table | Exact (2) |\n",
    "| 3 | Wooden Side Table | Partial (1) |\n",
    "| 4 | Metal Coffee Table | Irrelevant (0) |\n",
    "| 5 | Wooden Coffee Table (different) | Exact (2) |\n",
    "\n",
    "**Your task**: Calculate DCG and NDCG@5 by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'coffee table'\n",
      "Number of products with score > 0: 4446\n",
      "Max score: 7.5715\n",
      "Top 3 doc IDs: [20513 33290   608]\n"
     ]
    }
   ],
   "source": [
    "# Task 4b: Implement BM25 scoring\n",
    "\n",
    "def score_bm25(query: str, index: dict, doc_lengths: list[int], \n",
    "               num_docs: int, tokenizer, k1: float = 1.2, b: float = 0.75) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate BM25 scores for all documents given a query.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string\n",
    "        index: Inverted index\n",
    "        doc_lengths: List of document lengths\n",
    "        num_docs: Total number of documents\n",
    "        tokenizer: Tokenization function\n",
    "        k1: Term frequency saturation parameter (default 1.2)\n",
    "        b: Length normalization parameter (default 0.75)\n",
    "        \n",
    "    Returns:\n",
    "        Array of BM25 scores for each document\n",
    "    \"\"\"\n",
    "    query_tokens = tokenizer(query)\n",
    "    scores = np.zeros(num_docs)\n",
    "    \n",
    "    # Calculate average document length\n",
    "    avg_doc_len = np.mean(doc_lengths)\n",
    "    \n",
    "    # For each query term\n",
    "    for term in query_tokens:\n",
    "        df = get_df(term, index)\n",
    "        if df == 0:\n",
    "            continue  # Skip terms not in index\n",
    "        \n",
    "        # Calculate IDF for this term\n",
    "        idf = bm25_idf(df, num_docs)\n",
    "        \n",
    "        # Calculate score contribution for each document\n",
    "        for doc_id in range(num_docs):\n",
    "            tf = get_tf(term, doc_id, index)\n",
    "            if tf > 0:\n",
    "                # Length normalization\n",
    "                doc_len = doc_lengths[doc_id]\n",
    "                norm = 1 - b + b * (doc_len / avg_doc_len)\n",
    "                \n",
    "                # BM25 formula: IDF * (TF * (k1 + 1)) / (TF + k1 * norm)\n",
    "                tf_component = (tf * (k1 + 1)) / (tf + k1 * norm)\n",
    "                scores[doc_id] += idf * tf_component\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Test it\n",
    "test_query = \"coffee table\"\n",
    "test_scores = score_bm25(test_query, product_name_index, product_name_lengths, \n",
    "                         len(products), tokenize)\n",
    "\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(f\"Number of products with score > 0: {np.sum(test_scores > 0)}\")\n",
    "print(f\"Max score: {test_scores.max():.4f}\")\n",
    "print(f\"Top 3 doc IDs: {np.argsort(test_scores)[-3:][::-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### 4c. Implement NDCG function\n",
    "\n",
    "Now implement the NDCG calculation in code. Verify your implementation matches your hand calculation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for 'coffee table':\n",
      "                                       product_name             product_class  \\\n",
      "20513                                  coffee table  Coffee & Cocktail Tables   \n",
      "33290                                  coffee table  Coffee & Cocktail Tables   \n",
      "608                                    coffee table  Coffee & Cocktail Tables   \n",
      "5173                                   coffee table              Patio Tables   \n",
      "22679                                  coffee table  Coffee & Cocktail Tables   \n",
      "19750  a-37 coffee table in , matching coffee table  Coffee & Cocktail Tables   \n",
      "30371                          sanibel coffee table  Coffee & Cocktail Tables   \n",
      "27518                       manzanillo coffee table                End Tables   \n",
      "8082                            dortch coffee table  Coffee & Cocktail Tables   \n",
      "24726                        clintwood coffee table  Coffee & Cocktail Tables   \n",
      "\n",
      "          score  \n",
      "20513  7.571510  \n",
      "33290  7.571510  \n",
      "608    7.571510  \n",
      "5173   7.571510  \n",
      "22679  7.571510  \n",
      "19750  7.272181  \n",
      "30371  6.943483  \n",
      "27518  6.943483  \n",
      "8082   6.943483  \n",
      "24726  6.943483  \n"
     ]
    }
   ],
   "source": [
    "# Task 4c: Create search function\n",
    "\n",
    "def search_products(query: str, products_df: pd.DataFrame, index: dict, \n",
    "                   doc_lengths: list[int], tokenizer, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Search products and return top k results.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        products_df: DataFrame of products\n",
    "        index: Inverted index\n",
    "        doc_lengths: Document lengths\n",
    "        tokenizer: Tokenization function\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with top k products and their scores\n",
    "    \"\"\"\n",
    "    # Get BM25 scores\n",
    "    scores = score_bm25(query, index, doc_lengths, len(products_df), tokenizer)\n",
    "    \n",
    "    # Get top k indices (sorted by score, descending)\n",
    "    top_k_indices = np.argsort(scores)[-k:][::-1]\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = products_df.iloc[top_k_indices].copy()\n",
    "    results['score'] = scores[top_k_indices]\n",
    "    \n",
    "    # Filter out zero scores\n",
    "    results = results[results['score'] > 0]\n",
    "    \n",
    "    return results[['product_name', 'product_class', 'score']]\n",
    "\n",
    "# Test it\n",
    "results = search_products(\"coffee table\", products, product_name_index, \n",
    "                         product_name_lengths, tokenize, k=10)\n",
    "\n",
    "print(f\"Search results for 'coffee table':\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: 'wooden bed frame'\n",
      "============================================================\n",
      "                      product_name product_class     score\n",
      "mcdonell wooden frame platform bed          Beds 13.849290\n",
      "    wooden window frame wall dÃ©cor    Wall DÃ©cor 10.615593\n",
      "                         bed frame          Beds 10.396858\n",
      "                         bed frame    Bed Frames 10.396858\n",
      "                         bed frame    Bed Frames 10.396858\n",
      "\n",
      "============================================================\n",
      "Query: 'leather sofa'\n",
      "============================================================\n",
      "                                product_name                     product_class    score\n",
      "            chafin contemporary leather sofa Reception Sofas & Loveseats|Sofas 9.261937\n",
      "     124 '' wide leather match sofa & chaise                        Sectionals 8.031607\n",
      "          85 '' faux leather square arm sofa                             Sofas 8.031607\n",
      "          85 '' faux leather tuxedo arm sofa Reception Sofas & Loveseats|Sofas 8.031607\n",
      "hardee 86 '' genuine leather tuxedo arm sofa Reception Sofas & Loveseats|Sofas 7.531383\n",
      "\n",
      "============================================================\n",
      "Query: 'outdoor patio furniture'\n",
      "============================================================\n",
      "                                 product_name             product_class     score\n",
      "                outdoor patio furniture cover          Furniture Covers 14.892077\n",
      "           outdoor rattan patio furniture set Outdoor Conversation Sets 13.832596\n",
      "          7 piece outdoor patio furniture set Outdoor Conversation Sets 12.913854\n",
      "merlyn 6-piece outdoor garden patio furniture Outdoor Conversation Sets 12.913854\n",
      "      patio outdoor rattan furniture 4 pieces Outdoor Conversation Sets 12.913854\n",
      "\n",
      "============================================================\n",
      "Query: 'kids bedroom set'\n",
      "============================================================\n",
      "                                                              product_name     product_class    score\n",
      "                               capricorn platform configurable bedroom set               NaN 9.153506\n",
      "                                seleukos standard configurable bedroom set               NaN 9.153506\n",
      "hitchcock kids bedroom solid blackout thermal grommet single curtain panel Curtains & Drapes 8.765165\n",
      "                                      madalyn platform 4 piece bedroom set      Bedroom Sets 8.545542\n",
      "                    markovich platform solid wood configurable bedroom set               NaN 8.013309\n"
     ]
    }
   ],
   "source": [
    "# Task 4d: Test search on sample queries\n",
    "\n",
    "test_queries = [\n",
    "    \"wooden bed frame\",\n",
    "    \"leather sofa\",\n",
    "    \"outdoor patio furniture\",\n",
    "    \"kids bedroom set\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print('='*60)\n",
    "    results = search_products(query, products, product_name_index, \n",
    "                             product_name_lengths, tokenize, k=5)\n",
    "    print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 5: Evaluate Your Search Strategy\n",
    "\n",
    "Now let's evaluate our BM25 search across all queries in the WANDS dataset.\n",
    "\n",
    "### Evaluation Helper Functions (provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation functions (provided)\n",
    "\n",
    "def ndcg_at_k(relevance_scores: list, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate NDCG@k (Normalized Discounted Cumulative Gain).\n",
    "    \n",
    "    Args:\n",
    "        relevance_scores: List of relevance grades for results (in ranked order)\n",
    "        k: Number of results to consider\n",
    "        \n",
    "    Returns:\n",
    "        NDCG@k score between 0 and 1\n",
    "    \"\"\"\n",
    "    # DCG: sum of (relevance / log2(position + 1))\n",
    "    dcg = sum((rel / np.log2(i + 2)) for i, rel in enumerate(relevance_scores[:k]))\n",
    "    \n",
    "    # IDCG: DCG of perfect ranking\n",
    "    ideal_scores = sorted(relevance_scores, reverse=True)\n",
    "    idcg = sum((rel / np.log2(i + 2)) for i, rel in enumerate(ideal_scores[:k]))\n",
    "    \n",
    "    # NDCG\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    return dcg / idcg\n",
    "\n",
    "\n",
    "def evaluate_single_query(query: str, query_id: int, products_df: pd.DataFrame, \n",
    "                         labels_df: pd.DataFrame, search_func, k: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate a single query using NDCG@k.\n",
    "    \"\"\"\n",
    "    # Get search results\n",
    "    results = search_func(query, products_df, k=k)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Get ground truth labels for this query\n",
    "    query_labels = labels_df[labels_df['query_id'] == query_id]\n",
    "    \n",
    "    # Map product_id to relevance grade\n",
    "    relevance_map = dict(zip(query_labels['product_id'], query_labels['grade']))\n",
    "    \n",
    "    # Get product IDs from results (results.index contains the original product indices)\n",
    "    result_product_ids = products_df.loc[results.index, 'product_id'].tolist()\n",
    "    \n",
    "    # Get relevance scores\n",
    "    relevance_scores = [relevance_map.get(pid, 0) for pid in result_product_ids]\n",
    "    \n",
    "    # Calculate NDCG\n",
    "    return ndcg_at_k(relevance_scores, k)\n",
    "\n",
    "\n",
    "def evaluate_queries(queries_df, products_df, labels_df, search_func, k=10, verbose=False):\n",
    "    \"\"\"\n",
    "    Evaluate search function on all queries.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, row in queries_df.iterrows():\n",
    "        query_id = row['query_id']\n",
    "        query_text = row['query']\n",
    "        \n",
    "        ndcg = evaluate_single_query(query_text, query_id, products_df, \n",
    "                                     labels_df, search_func, k)\n",
    "        results.append({\n",
    "            'query_id': query_id,\n",
    "            'query': query_text,\n",
    "            'ndcg': ndcg\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Evaluated {len(results_df)} queries\")\n",
    "        print(f\"Mean NDCG@{k}: {results_df['ndcg'].mean():.4f}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### 5a. Run evaluation on all queries\n",
    "\n",
    "Create a search function and evaluate it on all queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 480 queries\n",
      "Mean NDCG@10: 0.8533\n",
      "\n",
      "Sample results:\n",
      "   query_id                      query      ndcg\n",
      "0         0                salon chair  0.959831\n",
      "1         1         smart coffee table  0.959856\n",
      "2         2                   dinosaur  0.892458\n",
      "3         3          turquoise pillows  0.796384\n",
      "4         4  chair and a half recliner  1.000000\n",
      "5         5          sofa with ottoman  0.976025\n",
      "6         6        acrylic clear chair  0.524344\n",
      "7         7           driftwood mirror  1.000000\n",
      "8         8       home sweet home sign  1.000000\n",
      "9         9      coffee table fire pit  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Task 5a: Run evaluation on all queries\n",
    "\n",
    "# Create a search function wrapper for evaluation\n",
    "def search_func(query: str, products_df: pd.DataFrame, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"Wrapper function for evaluation.\"\"\"\n",
    "    return search_products(query, products_df, product_name_index, \n",
    "                          product_name_lengths, tokenize, k=k)\n",
    "\n",
    "# Evaluate on all queries\n",
    "baseline_results = evaluate_queries(\n",
    "    queries, \n",
    "    products, \n",
    "    labels, \n",
    "    search_func, \n",
    "    k=10, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Show some results\n",
    "print(\"\\nSample results:\")\n",
    "print(baseline_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 5b. Identify failing queries\n",
    "\n",
    "Find queries where our search performed poorly (NDCG = 0 or very low). Analyze one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries with NDCG = 0: 34\n",
      "\n",
      "Sample failing queries:\n",
      "     query_id                           query  ndcg\n",
      "14         14             beds that have leds   0.0\n",
      "460       467  town & country living curtains   0.0\n",
      "458       465                  white abstract   0.0\n",
      "455       462                     large bases   0.0\n",
      "443       449             living room designs   0.0\n",
      "431       437    kitchen islands with seating   0.0\n",
      "415       421              dining room tables   0.0\n",
      "413       419               living room ideas   0.0\n",
      "395       401               glass lsmp shades   0.0\n",
      "389       395                     pantry grey   0.0\n",
      "\n",
      "============================================================\n",
      "Analyzing query: 'beds that have leds'\n",
      "============================================================\n",
      "\n",
      "Search results:\n",
      "                                            product_name  \\\n",
      "40178     tynes thank you for all that i have wall decal   \n",
      "25156              have a beautiful day metal wall dÃ©cor   \n",
      "28494            zula a love that is good decorative box   \n",
      "13599  olena art that sunflower from the sunflower st...   \n",
      "13182  that sunflower from the sunflower state by ole...   \n",
      "10648  love that rock music abstract 1-gang duplex ou...   \n",
      "14075  let that sh * * go buddhist-meditation yoga-bu...   \n",
      "10566  libourne funny owl drink to that owl drinking ...   \n",
      "2194   led strip lighting 2x5m 32.8 ft 5050 rgb 300 l...   \n",
      "21953  5m 5050 rgb smd led waterproof flexible strip ...   \n",
      "\n",
      "                      product_class      score  \n",
      "40178                 Wall Stickers  14.803000  \n",
      "25156                    Wall DÃ©cor   9.308811  \n",
      "28494              Decorative Boxes   7.775778  \n",
      "13599                Accent Pillows   6.959681  \n",
      "13182  Tapestries and Wall Hangings   6.959681  \n",
      "10648                   Wall Plates   6.959681  \n",
      "14075           Glassware & Barware   6.298617  \n",
      "10566                Mugs & Teacups   6.013044  \n",
      "2194                            NaN   5.958436  \n",
      "21953        Under Cabinet Lighting   5.958436  \n",
      "\n",
      "Number of relevant products in dataset: 1571\n",
      "\n",
      "Sample relevant products:\n",
      "                 product_name product_class\n",
      "aalt upholstered standard bed          Beds\n",
      "           aahil platform bed          Beds\n",
      "aalke solid wood platform bed          Beds\n"
     ]
    }
   ],
   "source": [
    "# Task 5b: Identify failing queries\n",
    "\n",
    "# Find queries with low NDCG scores\n",
    "failing_queries = baseline_results[baseline_results['ndcg'] == 0].sort_values('ndcg')\n",
    "\n",
    "print(f\"Number of queries with NDCG = 0: {len(failing_queries)}\")\n",
    "print(\"\\nSample failing queries:\")\n",
    "print(failing_queries.head(10))\n",
    "\n",
    "# Analyze one failing query in detail\n",
    "if len(failing_queries) > 0:\n",
    "    sample_query = failing_queries.iloc[0]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analyzing query: '{sample_query['query']}'\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Get search results\n",
    "    results = search_func(sample_query['query'], products, k=10)\n",
    "    print(\"\\nSearch results:\")\n",
    "    print(results)\n",
    "    \n",
    "    # Get ground truth labels\n",
    "    query_labels = labels[labels['query_id'] == sample_query['query_id']]\n",
    "    relevant_products = query_labels[query_labels['grade'] > 0]\n",
    "    print(f\"\\nNumber of relevant products in dataset: {len(relevant_products)}\")\n",
    "    \n",
    "    if len(relevant_products) > 0:\n",
    "        print(\"\\nSample relevant products:\")\n",
    "        sample_relevant = products[products['product_id'].isin(relevant_products['product_id'].head(3))]\n",
    "        print(sample_relevant[['product_name', 'product_class']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### 5c. Analyze the distribution\n",
    "\n",
    "Visualize the distribution of NDCG scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score Statistics:\n",
      "Mean: 0.8533\n",
      "Median: 0.9764\n",
      "Min: 0.0000\n",
      "Max: 1.0000\n",
      "Std Dev: 0.2701\n",
      "\n",
      "Performance breakdown:\n",
      "Perfect (NDCG = 1.0): 188 queries (39.2%)\n",
      "Good (NDCG >= 0.5): 435 queries (90.6%)\n",
      "Poor (NDCG < 0.5): 45 queries (9.4%)\n",
      "Failed (NDCG = 0): 34 queries (7.1%)\n"
     ]
    }
   ],
   "source": [
    "# Task 5c: Analyze the distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create histogram of NDCG scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(baseline_results['ndcg'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('NDCG@10 Score')\n",
    "plt.ylabel('Number of Queries')\n",
    "plt.title('Distribution of NDCG@10 Scores (Baseline Search)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"NDCG Score Statistics:\")\n",
    "print(f\"Mean: {baseline_results['ndcg'].mean():.4f}\")\n",
    "print(f\"Median: {baseline_results['ndcg'].median():.4f}\")\n",
    "print(f\"Min: {baseline_results['ndcg'].min():.4f}\")\n",
    "print(f\"Max: {baseline_results['ndcg'].max():.4f}\")\n",
    "print(f\"Std Dev: {baseline_results['ndcg'].std():.4f}\")\n",
    "\n",
    "# Percentage of queries by performance\n",
    "print(\"\\nPerformance breakdown:\")\n",
    "print(f\"Perfect (NDCG = 1.0): {(baseline_results['ndcg'] == 1.0).sum()} queries ({(baseline_results['ndcg'] == 1.0).mean()*100:.1f}%)\")\n",
    "print(f\"Good (NDCG >= 0.5): {(baseline_results['ndcg'] >= 0.5).sum()} queries ({(baseline_results['ndcg'] >= 0.5).mean()*100:.1f}%)\")\n",
    "print(f\"Poor (NDCG < 0.5): {(baseline_results['ndcg'] < 0.5).sum()} queries ({(baseline_results['ndcg'] < 0.5).mean()*100:.1f}%)\")\n",
    "print(f\"Failed (NDCG = 0): {(baseline_results['ndcg'] == 0).sum()} queries ({(baseline_results['ndcg'] == 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 6: Improve Search with Additional Fields\n",
    "\n",
    "Our baseline only searches the `product_name` field. Let's improve by adding more fields!\n",
    "\n",
    "### 6a. Index product_class field\n",
    "\n",
    "The `product_class` field contains the category of the product (e.g., \"Rugs\", \"Coffee Tables\"). This is a powerful signal!\n",
    "\n",
    "Create a search function that combines all three fields (name, description, class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices built for all fields:\n",
      "  - product_name: 29617 unique terms\n",
      "  - product_description: 38551 unique terms\n",
      "  - product_class: 960 unique terms\n",
      "\n",
      "============================================================\n",
      "Testing multi-field search on 'star wars rug'\n",
      "============================================================\n",
      "                                            product_name  \\\n",
      "34916  star wars rule the galaxy rectangular pillow c...   \n",
      "22734  â€œ star wars - darth vader â€ autographed framed...   \n",
      "36859                           star wars ep9 coffee mug   \n",
      "28470           star wars dark side storage accent trunk   \n",
      "21847       star wars tie fighter 10 light string lights   \n",
      "\n",
      "                                    product_class      score  \n",
      "34916            Licensed Products|Accent Pillows  21.864341  \n",
      "22734                  Licensed Products|Wall Art  21.405317  \n",
      "36859            Licensed Products|Mugs & Teacups  20.646758  \n",
      "28470  Licensed Products|Toy Boxes and Organizers  20.559840  \n",
      "21847          Holiday Lighting|Licensed Products  19.821561  \n"
     ]
    }
   ],
   "source": [
    "# Task 6a: Index product_class field\n",
    "\n",
    "# Build indices for all three fields\n",
    "product_name_index, product_name_lengths = build_index(\n",
    "    products['product_name'].tolist(), \n",
    "    tokenize\n",
    ")\n",
    "\n",
    "product_desc_index, product_desc_lengths = build_index(\n",
    "    products['product_description'].tolist(), \n",
    "    tokenize\n",
    ")\n",
    "\n",
    "product_class_index, product_class_lengths = build_index(\n",
    "    products['product_class'].tolist(), \n",
    "    tokenize\n",
    ")\n",
    "\n",
    "print(\"Indices built for all fields:\")\n",
    "print(f\"  - product_name: {len(product_name_index)} unique terms\")\n",
    "print(f\"  - product_description: {len(product_desc_index)} unique terms\")\n",
    "print(f\"  - product_class: {len(product_class_index)} unique terms\")\n",
    "\n",
    "# Create a three-field search function\n",
    "def search_products_multifield(query: str, products_df: pd.DataFrame, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Search across name, description, and class fields.\n",
    "    Combines scores using max (dismax approach).\n",
    "    \"\"\"\n",
    "    # Get scores from each field\n",
    "    name_scores = score_bm25(query, product_name_index, product_name_lengths, \n",
    "                            len(products_df), tokenize)\n",
    "    desc_scores = score_bm25(query, product_desc_index, product_desc_lengths, \n",
    "                            len(products_df), tokenize)\n",
    "    class_scores = score_bm25(query, product_class_index, product_class_lengths, \n",
    "                             len(products_df), tokenize)\n",
    "    \n",
    "    # Combine using max (dismax)\n",
    "    combined_scores = np.maximum(np.maximum(name_scores, desc_scores), class_scores)\n",
    "    \n",
    "    # Get top k\n",
    "    top_k_indices = np.argsort(combined_scores)[-k:][::-1]\n",
    "    \n",
    "    # Create results\n",
    "    results = products_df.iloc[top_k_indices].copy()\n",
    "    results['score'] = combined_scores[top_k_indices]\n",
    "    \n",
    "    # Filter zero scores\n",
    "    results = results[results['score'] > 0]\n",
    "    \n",
    "    return results[['product_name', 'product_class', 'score']]\n",
    "\n",
    "# Test it\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing multi-field search on 'star wars rug'\")\n",
    "print(\"=\"*60)\n",
    "results = search_products_multifield(\"star wars rug\", products, k=5)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### 6b. Evaluate three-field search\n",
    "\n",
    "Now evaluate your three-field search on all queries to see how it compares to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 480 queries\n",
      "Mean NDCG@10: 0.8240\n",
      "\n",
      "Sample results:\n",
      "   query_id                      query      ndcg\n",
      "0         0                salon chair  1.000000\n",
      "1         1         smart coffee table  0.963167\n",
      "2         2                   dinosaur  1.000000\n",
      "3         3          turquoise pillows  0.757890\n",
      "4         4  chair and a half recliner  1.000000\n",
      "5         5          sofa with ottoman  0.940182\n",
      "6         6        acrylic clear chair  1.000000\n",
      "7         7           driftwood mirror  1.000000\n",
      "8         8       home sweet home sign  1.000000\n",
      "9         9      coffee table fire pit  1.000000\n",
      "\n",
      "============================================================\n",
      "COMPARISON: Baseline vs Multi-Field\n",
      "============================================================\n",
      "Baseline Mean NDCG@10:    0.8533\n",
      "Multi-Field Mean NDCG@10: 0.8240\n",
      "Improvement:              -0.0292\n"
     ]
    }
   ],
   "source": [
    "# Task 6b: Evaluate three-field search\n",
    "\n",
    "# Evaluate the multi-field search\n",
    "multifield_results = evaluate_queries(\n",
    "    queries,\n",
    "    products,\n",
    "    labels,\n",
    "    search_products_multifield,\n",
    "    k=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nSample results:\")\n",
    "print(multifield_results.head(10))\n",
    "\n",
    "# Compare to baseline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Baseline vs Multi-Field\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Baseline Mean NDCG@10:    {baseline_results['ndcg'].mean():.4f}\")\n",
    "print(f\"Multi-Field Mean NDCG@10: {multifield_results['ndcg'].mean():.4f}\")\n",
    "print(f\"Improvement:              {(multifield_results['ndcg'].mean() - baseline_results['ndcg'].mean()):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### 6c. Compare to baseline\n",
    "\n",
    "Analyze which queries improved and which degraded when using three-field search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries that IMPROVED: 122\n",
      "\n",
      "Top 5 improvements:\n",
      "                              query  ndcg_baseline  ndcg_multifield  \\\n",
      "219        wisdom stone river 3-3/4            0.0         1.000000   \n",
      "460  town & country living curtains            0.0         0.921787   \n",
      "135   low profile loveseat recliner            0.0         0.905104   \n",
      "167                        printers            0.0         0.888111   \n",
      "252  high weight capacity bunk beds            0.0         0.776161   \n",
      "\n",
      "     improvement  \n",
      "219     1.000000  \n",
      "460     0.921787  \n",
      "135     0.905104  \n",
      "167     0.888111  \n",
      "252     0.776161  \n",
      "\n",
      "Queries that DEGRADED: 245\n",
      "\n",
      "Top 5 degradations:\n",
      "                                                 query  ndcg_baseline  \\\n",
      "472                    pictures to hang over fireplace       1.000000   \n",
      "133                             outdoor light fixtures       1.000000   \n",
      "296                               circle cabinet pulls       0.946902   \n",
      "31                               burnt orange curtains       1.000000   \n",
      "186  bedroom wall decor floral, multicolored with s...       0.967094   \n",
      "\n",
      "     ndcg_multifield  improvement  \n",
      "472         0.000000    -1.000000  \n",
      "133         0.000000    -1.000000  \n",
      "296         0.289065    -0.657838  \n",
      "31          0.356207    -0.643793  \n",
      "186         0.333333    -0.633761  \n",
      "\n",
      "Queries UNCHANGED: 113\n",
      "\n",
      "============================================================\n",
      "Example improved query: 'wisdom stone river 3-3/4'\n",
      "Baseline NDCG: 0.0000\n",
      "Multi-field NDCG: 1.0000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Task 6c: Compare to baseline\n",
    "\n",
    "# Merge results to compare\n",
    "comparison = baseline_results.merge(\n",
    "    multifield_results, \n",
    "    on=['query_id', 'query'], \n",
    "    suffixes=('_baseline', '_multifield')\n",
    ")\n",
    "\n",
    "# Calculate improvement\n",
    "comparison['improvement'] = comparison['ndcg_multifield'] - comparison['ndcg_baseline']\n",
    "\n",
    "# Queries that improved\n",
    "improved = comparison[comparison['improvement'] > 0].sort_values('improvement', ascending=False)\n",
    "print(f\"Queries that IMPROVED: {len(improved)}\")\n",
    "print(\"\\nTop 5 improvements:\")\n",
    "print(improved[['query', 'ndcg_baseline', 'ndcg_multifield', 'improvement']].head())\n",
    "\n",
    "# Queries that degraded\n",
    "degraded = comparison[comparison['improvement'] < 0].sort_values('improvement')\n",
    "print(f\"\\nQueries that DEGRADED: {len(degraded)}\")\n",
    "print(\"\\nTop 5 degradations:\")\n",
    "print(degraded[['query', 'ndcg_baseline', 'ndcg_multifield', 'improvement']].head())\n",
    "\n",
    "# Queries unchanged\n",
    "unchanged = comparison[comparison['improvement'] == 0]\n",
    "print(f\"\\nQueries UNCHANGED: {len(unchanged)}\")\n",
    "\n",
    "# Analyze one improved query\n",
    "if len(improved) > 0:\n",
    "    sample = improved.iloc[0]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Example improved query: '{sample['query']}'\")\n",
    "    print(f\"Baseline NDCG: {sample['ndcg_baseline']:.4f}\")\n",
    "    print(f\"Multi-field NDCG: {sample['ndcg_multifield']:.4f}\")\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 7: Query Understanding with LLM\n",
    "\n",
    "Sometimes users search for \"star wars rug\" when they really want a \"rug with Star Wars theme\". An LLM can help us understand what the user is actually looking for!\n",
    "\n",
    "### 7a. Extract product type from query\n",
    "\n",
    "Write a function using LiteLLM with structured outputs (Pydantic) to extract key information from a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7a: Extract product type, theme, material, color, and other information from the query\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class QueryUnderstanding(BaseModel):\n",
    "    \"\"\"Structured output for query understanding.\"\"\"\n",
    "    product_type: Optional[str] = Field(None, description=\"The type of product (e.g., 'rug', 'table', 'sofa')\")\n",
    "    theme: Optional[str] = Field(None, description=\"Theme or style (e.g., 'star wars', 'modern', 'rustic')\")\n",
    "    material: Optional[str] = Field(None, description=\"Material (e.g., 'wooden', 'leather', 'metal')\")\n",
    "    color: Optional[str] = Field(None, description=\"Color (e.g., 'blue', 'red', 'black')\")\n",
    "    other_attributes: Optional[str] = Field(None, description=\"Any other relevant attributes\")\n",
    "\n",
    "def understand_query(query: str) -> QueryUnderstanding:\n",
    "    \"\"\"\n",
    "    Use LLM to extract structured information from a search query.\n",
    "    \"\"\"\n",
    "    response = litellm.completion(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are a search query analyzer for an e-commerce furniture store.\n",
    "Extract key attributes from user queries. Be concise and extract only what's clearly present.\n",
    "If an attribute isn't mentioned, leave it as null.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Extract product attributes from this query: '{query}'\"\n",
    "            }\n",
    "        ],\n",
    "        response_format=QueryUnderstanding,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    # Parse the response\n",
    "    import json\n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "    return QueryUnderstanding(**result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing query understanding:\n",
      "\n",
      "Query: 'star wars rug'\n",
      "  Product Type: rug\n",
      "  Theme: star wars\n",
      "  Material: None\n",
      "  Color: None\n",
      "  Other: None\n",
      "\n",
      "Query: 'wooden coffee table'\n",
      "  Product Type: table\n",
      "  Theme: None\n",
      "  Material: wooden\n",
      "  Color: None\n",
      "  Other: coffee\n",
      "\n",
      "Query: 'blue leather sofa'\n",
      "  Product Type: sofa\n",
      "  Theme: None\n",
      "  Material: leather\n",
      "  Color: blue\n",
      "  Other: None\n",
      "\n",
      "Query: 'modern metal bookshelf'\n",
      "  Product Type: bookshelf\n",
      "  Theme: modern\n",
      "  Material: metal\n",
      "  Color: None\n",
      "  Other: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"star wars rug\",\n",
    "    \"wooden coffee table\",\n",
    "    \"blue leather sofa\",\n",
    "    \"modern metal bookshelf\"\n",
    "]\n",
    "\n",
    "print(\"Testing query understanding:\\n\")\n",
    "for q in test_queries:\n",
    "    understanding = understand_query(q)\n",
    "    print(f\"Query: '{q}'\")\n",
    "    print(f\"  Product Type: {understanding.product_type}\")\n",
    "    print(f\"  Theme: {understanding.theme}\")\n",
    "    print(f\"  Material: {understanding.material}\")\n",
    "    print(f\"  Color: {understanding.color}\")\n",
    "    print(f\"  Other: {understanding.other_attributes}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### 7b. Create an LLM-enhanced search\n",
    "\n",
    "Use the extracted product type to boost matching results. If the LLM identifies \"rug\" as the product type, boost products where `product_class` contains \"rug\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LLM-enhanced search:\n",
      "\n",
      "Query: 'star wars rug'\n",
      "============================================================\n",
      "\n",
      "Multi-field results:\n",
      "                                            product_name  \\\n",
      "34916  star wars rule the galaxy rectangular pillow c...   \n",
      "22734  â€œ star wars - darth vader â€ autographed framed...   \n",
      "36859                           star wars ep9 coffee mug   \n",
      "28470           star wars dark side storage accent trunk   \n",
      "21847       star wars tie fighter 10 light string lights   \n",
      "\n",
      "                                    product_class      score  \n",
      "34916            Licensed Products|Accent Pillows  21.864341  \n",
      "22734                  Licensed Products|Wall Art  21.405317  \n",
      "36859            Licensed Products|Mugs & Teacups  20.646758  \n",
      "28470  Licensed Products|Toy Boxes and Organizers  20.559840  \n",
      "21847          Holiday Lighting|Licensed Products  19.821561  \n",
      "\n",
      "LLM-enhanced results:\n",
      "                                            product_name  \\\n",
      "34916  star wars rule the galaxy rectangular pillow c...   \n",
      "22734  â€œ star wars - darth vader â€ autographed framed...   \n",
      "36859                           star wars ep9 coffee mug   \n",
      "28470           star wars dark side storage accent trunk   \n",
      "21847       star wars tie fighter 10 light string lights   \n",
      "\n",
      "                                    product_class      score  \n",
      "34916            Licensed Products|Accent Pillows  21.864341  \n",
      "22734                  Licensed Products|Wall Art  21.405317  \n",
      "36859            Licensed Products|Mugs & Teacups  20.646758  \n",
      "28470  Licensed Products|Toy Boxes and Organizers  20.559840  \n",
      "21847          Holiday Lighting|Licensed Products  19.821561  \n"
     ]
    }
   ],
   "source": [
    "# Task 7b: Create an LLM-enhanced search\n",
    "\n",
    "def search_products_llm_enhanced(query: str, products_df: pd.DataFrame, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Search with LLM-based query understanding.\n",
    "    Boosts products matching the extracted product_type.\n",
    "    \"\"\"\n",
    "    # Get base multi-field scores\n",
    "    name_scores = score_bm25(query, product_name_index, product_name_lengths, \n",
    "                            len(products_df), tokenize)\n",
    "    desc_scores = score_bm25(query, product_desc_index, product_desc_lengths, \n",
    "                            len(products_df), tokenize)\n",
    "    class_scores = score_bm25(query, product_class_index, product_class_lengths, \n",
    "                             len(products_df), tokenize)\n",
    "    \n",
    "    # Combine using max\n",
    "    combined_scores = np.maximum(np.maximum(name_scores, desc_scores), class_scores)\n",
    "    \n",
    "    # Use LLM to understand query\n",
    "    try:\n",
    "        understanding = understand_query(query)\n",
    "        \n",
    "        # Boost products matching the product_type\n",
    "        if understanding.product_type:\n",
    "            boost_factor = 2.0  # Boost multiplier\n",
    "            product_type_lower = understanding.product_type.lower()\n",
    "            \n",
    "            # Check which products match the product type\n",
    "            for idx, row in products_df.iterrows():\n",
    "                product_class_lower = str(row['product_class']).lower()\n",
    "                if product_type_lower in product_class_lower:\n",
    "                    combined_scores[idx] *= boost_factor\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"LLM query understanding failed: {e}\")\n",
    "        # Fall back to regular multi-field search\n",
    "        pass\n",
    "    \n",
    "    # Get top k\n",
    "    top_k_indices = np.argsort(combined_scores)[-k:][::-1]\n",
    "    \n",
    "    # Create results\n",
    "    results = products_df.iloc[top_k_indices].copy()\n",
    "    results['score'] = combined_scores[top_k_indices]\n",
    "    \n",
    "    # Filter zero scores\n",
    "    results = results[results['score'] > 0]\n",
    "    \n",
    "    return results[['product_name', 'product_class', 'score']]\n",
    "\n",
    "# Test it\n",
    "print(\"Testing LLM-enhanced search:\\n\")\n",
    "test_query = \"star wars rug\"\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nMulti-field results:\")\n",
    "multifield_res = search_products_multifield(test_query, products, k=5)\n",
    "print(multifield_res)\n",
    "\n",
    "print(\"\\nLLM-enhanced results:\")\n",
    "llm_res = search_products_llm_enhanced(test_query, products, k=5)\n",
    "print(llm_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LLM-enhanced search (this may take a few minutes due to API calls)...\n",
      "\n",
      "Evaluated 480 queries\n",
      "Mean NDCG@10: 0.8340\n",
      "\n",
      "============================================================\n",
      "FINAL COMPARISON\n",
      "============================================================\n",
      "Baseline (name only):     0.8533\n",
      "Multi-Field:              0.8240\n",
      "LLM-Enhanced:             0.8340\n",
      "\n",
      "Improvements:\n",
      "Multi-Field vs Baseline:  -0.0292\n",
      "LLM vs Multi-Field:       0.0100\n",
      "LLM vs Baseline:          -0.0192\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LLM-enhanced search on all queries\n",
    "\n",
    "print(\"Evaluating LLM-enhanced search (this may take a few minutes due to API calls)...\\n\")\n",
    "\n",
    "llm_enhanced_results = evaluate_queries(\n",
    "    queries,\n",
    "    products,\n",
    "    labels,\n",
    "    search_products_llm_enhanced,\n",
    "    k=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Compare all three approaches\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Baseline (name only):     {baseline_results['ndcg'].mean():.4f}\")\n",
    "print(f\"Multi-Field:              {multifield_results['ndcg'].mean():.4f}\")\n",
    "print(f\"LLM-Enhanced:             {llm_enhanced_results['ndcg'].mean():.4f}\")\n",
    "print(\"\\nImprovements:\")\n",
    "print(f\"Multi-Field vs Baseline:  {(multifield_results['ndcg'].mean() - baseline_results['ndcg'].mean()):.4f}\")\n",
    "print(f\"LLM vs Multi-Field:       {(llm_enhanced_results['ndcg'].mean() - multifield_results['ndcg'].mean()):.4f}\")\n",
    "print(f\"LLM vs Baseline:          {(llm_enhanced_results['ndcg'].mean() - baseline_results['ndcg'].mean()):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 8: Submit via Pull Request\n",
    "\n",
    "Now let's submit your work using the Git workflow from previous homeworks.\n",
    "- [ ] Create a new branch called `homework-3`\n",
    "- [ ] Commit you work and push it to the branch\n",
    "- [ ] Create a PR with a nice description of your changes\n",
    "- [ ] Merge the PR to your main branch\n",
    "  \n",
    "**The TA will verify your submission by checking the merged PR on your GitHub repo.**\n",
    "\n",
    "**Also remember to submit your homework on Blackboard!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
